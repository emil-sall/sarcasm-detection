# Sarcasm Detection with Transformer Model Encoders
This approaches the problem of detecting sarcasm in a text. A text can be sarcastic on its own or given a context, both scenarios are considered and it can be seen as a binary classification problem. Sarcasm is something that could be hard to understand even in speech and it has been showed that humans often relies more on the intonation in a voice than the context to understand sarcasm. To approach a problem of sarcasm detection in text, where the intonation in a voice is non existent, yields a challenge where the text itself and a possible context is the only thing that can be relied upon.

The problem is approached by using the encoder part of transformer models. The data used consists of tweets, reddit comments and news headlines collected from multiple sarcasm-annotated datasets. During the project due to hardware limitations, the amount of data that could be used in the model was heavily reduced from about 1 million data points to about 50000. This of course effected the result and compared to the baseline which was trained on about 1.5 million reddit comments, the model presented here is still performing similarly to the baseline. 
